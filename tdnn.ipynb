{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\MTP\n"
     ]
    }
   ],
   "source": [
    "cd F:/MTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.listdir('EmoDB/wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_code = {\n",
    "    'W':0, #anger\n",
    "    'L':1, #boredom\n",
    "    'E':2, #disgust\n",
    "    'A':3, #fear\n",
    "    'F':4, #happy\n",
    "    'T':5, #sad\n",
    "    'N':6  #neutral\n",
    "}\n",
    "\n",
    "speaker_code = {\n",
    "    '03':0,\n",
    "    '08':1,\n",
    "    '09':2,\n",
    "    '10':3,\n",
    "    '11':4,\n",
    "    '12':5,\n",
    "    '13':6,\n",
    "    '14':7,\n",
    "    '15':8,\n",
    "    '16':9\n",
    "}\n",
    "\n",
    "gender_code = {\n",
    "    '03':0,\n",
    "    '08':1,\n",
    "    '09':1,\n",
    "    '10':0,\n",
    "    '11':0,\n",
    "    '12':0,\n",
    "    '13':1,\n",
    "    '14':1,\n",
    "    '15':0,\n",
    "    '16':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_id = {0:\"03\",1:\"08\",2:\"09\",3:\"10\",4:\"11\",5:\"12\",6:\"13\",7:\"14\",8:\"15\",9:\"16\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path, test_key,valid_key, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.files = os.listdir(self.dir_path)\n",
    "        self.test_key = test_key\n",
    "        self.valid_key = valid_key\n",
    "        self.melspecs,self.Y = self.loadData(dir_path)\n",
    "        print(len(self.melspecs),len(self.Y))\n",
    "        \n",
    "    def loadData(self,dir_path):\n",
    "        files = os.listdir(dir_path)\n",
    "        train_keys = list((spk_id[i] for i in range(10) if i not in [self.test_key,self.valid_key]))\n",
    "        melspecs = []\n",
    "        Y = []\n",
    "        for key in train_keys:\n",
    "            for file in files:\n",
    "                if file[:2]==key:\n",
    "                    r, sr = librosa.load(dir_path + file, res_type='kaiser_fast')\n",
    "                    mfc = librosa.feature.mfcc(y=r, sr=sr,n_fft = 512, hop_length=160, win_length=320)\n",
    "                    temp = self.chunk(torch.Tensor(mfc))\n",
    "                    melspecs.extend(temp)\n",
    "                    for _ in range(len(temp)):\n",
    "                        y = torch.zeros(7,dtype = int)\n",
    "                        y[emotion_code[file[5]]]=1\n",
    "                        Y.append(y)\n",
    "        return melspecs,Y\n",
    "    \n",
    "    def chunk(self,melspec):\n",
    "        melspec = melspec.transpose(0,1)\n",
    "        res = []\n",
    "        for i in range(0,melspec.size(0),50):\n",
    "            temp = melspec[i:i+100,:]\n",
    "            if temp.size(0)==100:\n",
    "                res.append(temp)\n",
    "        return res        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.melspecs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.melspecs[idx],self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2755 2755\n"
     ]
    }
   ],
   "source": [
    "ds = TrainDataset(\"EmoDB/wav/\",3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(ds, batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path,valid_key, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.files = os.listdir(self.dir_path)\n",
    "        self.valid_key = valid_key\n",
    "        self.melspecs,self.Y = self.loadData(dir_path)\n",
    "        print(len(self.melspecs),len(self.Y))\n",
    "        \n",
    "    def loadData(self,dir_path):\n",
    "        files = os.listdir(dir_path)\n",
    "        melspecs = []\n",
    "        Y = []\n",
    "        for file in files:\n",
    "            if file[:2]==spk_id[self.valid_key]:\n",
    "                r, sr = librosa.load(dir_path + file, res_type='kaiser_fast')\n",
    "                melspec = librosa.feature.mfcc(y=r, sr=sr,n_fft = 512, hop_length=160, win_length=320)\n",
    "                temp = self.chunk(torch.Tensor(melspec))\n",
    "                melspecs.extend(temp)\n",
    "                for _ in range(len(temp)):\n",
    "                    y = torch.zeros(7,dtype = int)\n",
    "                    y[emotion_code[file[5]]]=1\n",
    "                    Y.append(y)\n",
    "        return melspecs,Y\n",
    "    \n",
    "    def chunk(self,melspec):\n",
    "        melspec = melspec.transpose(0,1)\n",
    "        res = []\n",
    "        for i in range(0,melspec.size(0),50):\n",
    "            temp = melspec[i:i+100,:]\n",
    "            if temp.size(0)==100:\n",
    "                res.append(temp)\n",
    "        return res        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.melspecs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.melspecs[idx],self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357 357\n"
     ]
    }
   ],
   "source": [
    "validset = ValidDataset(\"EmoDB/wav/\",4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(validset, batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path, test_key, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.files = os.listdir(self.dir_path)\n",
    "        self.test_key = test_key\n",
    "        self.melspecs,self.Y = self.loadData(dir_path)\n",
    "        print(len(self.melspecs),len(self.Y))\n",
    "        \n",
    "    def loadData(self,dir_path):\n",
    "        files = os.listdir(dir_path)\n",
    "        melspecs = []\n",
    "        Y = []\n",
    "        key = spk_id[self.test_key]\n",
    "        for file in files:\n",
    "            if file[:2]==key:\n",
    "                r, sr = librosa.load(dir_path + file, res_type='kaiser_fast')\n",
    "                melspec = librosa.feature.mfcc(y=r, sr=sr,n_fft = 512, hop_length=160, win_length=320)\n",
    "                melspec = melspec.transpose()\n",
    "                melspecs.append(melspec)\n",
    "                y = torch.zeros(7,dtype = int)\n",
    "                y[emotion_code[file[5]]]=1\n",
    "                Y.append(y)\n",
    "        return melspecs,Y\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.melspecs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.melspecs[idx],self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 38\n"
     ]
    }
   ],
   "source": [
    "testset = TestDataset(\"EmoDB/wav/\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(testloader, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "#         print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(testset, batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TDNN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "                    self, \n",
    "                    input_dim=23, \n",
    "                    output_dim=512,\n",
    "                    context_size=5,\n",
    "                    stride=1,\n",
    "                    dilation=1,\n",
    "                    batch_norm=False,\n",
    "                    dropout_p=0.2\n",
    "                ):\n",
    "        super(TDNN, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.stride = stride\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dilation = dilation\n",
    "        self.dropout_p = dropout_p\n",
    "        self.batch_norm = batch_norm\n",
    "      \n",
    "        self.kernel = nn.Linear(input_dim*context_size, output_dim)\n",
    "        self.nonlinearity = nn.ReLU()\n",
    "        if self.batch_norm:\n",
    "            self.bn = nn.BatchNorm1d(output_dim)\n",
    "        if self.dropout_p:\n",
    "            self.drop = nn.Dropout(p=self.dropout_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        _, _, d = x.shape\n",
    "        assert (d == self.input_dim), 'Input dimension was wrong. Expected ({}), got ({})'.format(self.input_dim, d)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Unfold input into smaller temporal contexts\n",
    "        x = F.unfold(\n",
    "                        x, \n",
    "                        (self.context_size, self.input_dim), \n",
    "                        stride=(1,self.input_dim), \n",
    "                        dilation=(self.dilation,1)\n",
    "                    )\n",
    "\n",
    "        # N, output_dim*context_size, new_t = x.shape\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.kernel(x.float())\n",
    "        x = self.nonlinearity(x)\n",
    "        \n",
    "        if self.dropout_p:\n",
    "            x = self.drop(x)\n",
    "\n",
    "        if self.batch_norm:\n",
    "            x = x.transpose(1,2)\n",
    "            x = self.bn(x)\n",
    "            x = x.transpose(1,2)\n",
    "\n",
    "        return x\n",
    "import torch.nn as nn\n",
    "# from models.tdnn import TDNN\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class X_vector(nn.Module):\n",
    "    def __init__(self, input_dim = 20, num_classes=7):\n",
    "        super(X_vector, self).__init__()\n",
    "        self.tdnn1 = TDNN(input_dim=input_dim, output_dim=512, context_size=5, dilation=1,dropout_p=0.5)\n",
    "        self.tdnn2 = TDNN(input_dim=512, output_dim=512, context_size=3, dilation=1,dropout_p=0.5)\n",
    "        self.tdnn3 = TDNN(input_dim=512, output_dim=512, context_size=2, dilation=2,dropout_p=0.5)\n",
    "        self.tdnn4 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=1,dropout_p=0.5)\n",
    "        self.tdnn5 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=3,dropout_p=0.5)\n",
    "        #### Frame levelPooling\n",
    "        self.segment6 = nn.Linear(1024, 512)\n",
    "        self.segment7 = nn.Linear(512, 512)\n",
    "        self.output = nn.Linear(512, num_classes)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, inputs):\n",
    "        tdnn1_out = self.tdnn1(inputs)\n",
    "#         return tdnn1_out\n",
    "        tdnn2_out = self.tdnn2(tdnn1_out)\n",
    "        tdnn3_out = self.tdnn3(tdnn2_out)\n",
    "        tdnn4_out = self.tdnn4(tdnn3_out)\n",
    "        tdnn5_out = self.tdnn5(tdnn4_out)\n",
    "        ### Stat Pool\n",
    "        mean = torch.mean(tdnn5_out,1)\n",
    "        std = torch.std(tdnn5_out,1)\n",
    "        stat_pooling = torch.cat((mean,std),1)\n",
    "        segment6_out = self.segment6(stat_pooling)\n",
    "        x_vec = self.segment7(segment6_out)\n",
    "        predictions = self.output(x_vec)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feats = [4,100,20]\n",
    "input = torch.rand(input_feats)\n",
    "model = X_vector()\n",
    "out = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0170, -0.0404, -0.0174, -0.0133,  0.0375,  0.0010,  0.0251],\n",
       "        [ 0.0170, -0.0417, -0.0166, -0.0157,  0.0377, -0.0012,  0.0280],\n",
       "        [ 0.0174, -0.0404, -0.0149, -0.0133,  0.0371, -0.0003,  0.0263],\n",
       "        [ 0.0173, -0.0411, -0.0154, -0.0155,  0.0387, -0.0016,  0.0273]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0, betas=(0.9, 0.98), eps=1e-9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader,epoch):\n",
    "    running_loss = 0.0\n",
    "    correct=0\n",
    "    total=0\n",
    "    train_loss_list=[]\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs.requires_grad = True\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        labels = torch.argmax(labels,dim =1)\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        mean_loss = np.mean(np.asarray(train_loss_list))\n",
    "        s = 0.0\n",
    "    for param in model.parameters():\n",
    "        s += torch.sum(param)\n",
    "    return s\n",
    "#         if i%100==0:\n",
    "#             print('Iteration - {} Epoch - {} Total training loss - {}'.format(i,epoch,mean_loss))\n",
    "    print(\"train accuracy after epoch \" +str(epoch) +\" is \" + str(100 * correct / total))\n",
    "            \n",
    "def validation(valid_dataloader,epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss_list=[]\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(valid_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            labels = torch.argmax(labels,dim =1)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss_list.append(loss.item())\n",
    "#             if i%100==0:\n",
    "#                 print('Iteration - {} Epoch - {} Loss - {}'.format(i,epoch,np.mean(np.asarray(val_loss_list))))\n",
    "        print(\"valid accuracy after epoch \"+str(epoch) +\" is \" + str(100 * correct / total))        \n",
    "        mean_loss = np.mean(np.asarray(val_loss_list))\n",
    "#         print('Total validation loss {} after {} epochs'.format(mean_loss,epoch))\n",
    "        model_save_path = os.path.join( 'best_check_point_'+str(epoch)+'_'+str(mean_loss))\n",
    "        state_dict = {'model': model.state_dict(),'optimizer': optimizer.state_dict(),'epoch': epoch}\n",
    "        torch.save(state_dict, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after epoch 0 is 55.35390199637023\n",
      "valid accuracy after epoch 0 is 33.05322128851541\n",
      "train accuracy after epoch 1 is 56.152450090744104\n",
      "valid accuracy after epoch 1 is 24.089635854341736\n",
      "train accuracy after epoch 2 is 56.91470054446461\n",
      "valid accuracy after epoch 2 is 32.212885154061624\n",
      "train accuracy after epoch 3 is 56.8421052631579\n",
      "valid accuracy after epoch 3 is 22.689075630252102\n",
      "train accuracy after epoch 4 is 57.168784029038115\n",
      "valid accuracy after epoch 4 is 22.689075630252102\n",
      "train accuracy after epoch 5 is 57.53176043557169\n",
      "valid accuracy after epoch 5 is 21.568627450980394\n",
      "train accuracy after epoch 6 is 57.313974591651544\n",
      "valid accuracy after epoch 6 is 21.288515406162464\n",
      "train accuracy after epoch 7 is 58.87477313974592\n",
      "valid accuracy after epoch 7 is 36.97478991596638\n",
      "train accuracy after epoch 8 is 56.95099818511797\n",
      "valid accuracy after epoch 8 is 31.092436974789916\n",
      "train accuracy after epoch 9 is 55.82577132486389\n",
      "valid accuracy after epoch 9 is 26.050420168067227\n",
      "train accuracy after epoch 10 is 56.95099818511797\n",
      "valid accuracy after epoch 10 is 26.050420168067227\n",
      "train accuracy after epoch 11 is 57.3502722323049\n",
      "valid accuracy after epoch 11 is 21.288515406162464\n",
      "train accuracy after epoch 12 is 58.22141560798548\n",
      "valid accuracy after epoch 12 is 21.008403361344538\n",
      "train accuracy after epoch 13 is 56.62431941923775\n",
      "valid accuracy after epoch 13 is 21.84873949579832\n",
      "train accuracy after epoch 14 is 57.168784029038115\n",
      "valid accuracy after epoch 14 is 26.89075630252101\n",
      "train accuracy after epoch 15 is 57.45916515426497\n",
      "valid accuracy after epoch 15 is 21.84873949579832\n",
      "train accuracy after epoch 16 is 56.261343012704174\n",
      "valid accuracy after epoch 16 is 28.571428571428573\n",
      "train accuracy after epoch 17 is 57.93103448275862\n",
      "valid accuracy after epoch 17 is 21.568627450980394\n",
      "train accuracy after epoch 18 is 58.00362976406534\n",
      "valid accuracy after epoch 18 is 19.327731092436974\n",
      "train accuracy after epoch 19 is 56.33393829401089\n",
      "valid accuracy after epoch 19 is 19.88795518207283\n",
      "train accuracy after epoch 20 is 57.3502722323049\n",
      "valid accuracy after epoch 20 is 19.327731092436974\n",
      "train accuracy after epoch 21 is 59.382940108892925\n",
      "valid accuracy after epoch 21 is 23.249299719887954\n",
      "train accuracy after epoch 22 is 59.16515426497278\n",
      "valid accuracy after epoch 22 is 23.249299719887954\n",
      "train accuracy after epoch 23 is 57.74954627949183\n",
      "valid accuracy after epoch 23 is 19.327731092436974\n",
      "train accuracy after epoch 24 is 60.03629764065336\n",
      "valid accuracy after epoch 24 is 21.008403361344538\n",
      "train accuracy after epoch 25 is 58.475499092558984\n",
      "valid accuracy after epoch 25 is 22.408963585434172\n",
      "train accuracy after epoch 26 is 57.241379310344826\n",
      "valid accuracy after epoch 26 is 33.61344537815126\n",
      "train accuracy after epoch 27 is 58.98366606170599\n",
      "valid accuracy after epoch 27 is 19.88795518207283\n",
      "train accuracy after epoch 28 is 57.49546279491833\n",
      "valid accuracy after epoch 28 is 18.48739495798319\n",
      "train accuracy after epoch 29 is 56.98729582577133\n",
      "valid accuracy after epoch 29 is 18.76750700280112\n",
      "train accuracy after epoch 30 is 58.91107078039927\n",
      "valid accuracy after epoch 30 is 20.72829131652661\n",
      "train accuracy after epoch 31 is 57.6043557168784\n",
      "valid accuracy after epoch 31 is 20.72829131652661\n",
      "train accuracy after epoch 32 is 57.96733212341198\n",
      "valid accuracy after epoch 32 is 21.008403361344538\n",
      "train accuracy after epoch 33 is 57.023593466424686\n",
      "valid accuracy after epoch 33 is 28.011204481792717\n",
      "train accuracy after epoch 34 is 57.6043557168784\n",
      "valid accuracy after epoch 34 is 22.969187675070028\n",
      "train accuracy after epoch 35 is 58.148820326678766\n",
      "valid accuracy after epoch 35 is 19.607843137254903\n",
      "train accuracy after epoch 36 is 59.12885662431942\n",
      "valid accuracy after epoch 36 is 20.168067226890756\n",
      "train accuracy after epoch 37 is 57.89473684210526\n",
      "valid accuracy after epoch 37 is 19.047619047619047\n",
      "train accuracy after epoch 38 is 59.16515426497278\n",
      "valid accuracy after epoch 38 is 18.76750700280112\n",
      "train accuracy after epoch 39 is 57.05989110707804\n",
      "valid accuracy after epoch 39 is 19.327731092436974\n",
      "train accuracy after epoch 40 is 59.23774954627949\n",
      "valid accuracy after epoch 40 is 18.48739495798319\n",
      "train accuracy after epoch 41 is 58.11252268602541\n",
      "valid accuracy after epoch 41 is 22.969187675070028\n",
      "train accuracy after epoch 42 is 58.98366606170599\n",
      "valid accuracy after epoch 42 is 22.408963585434172\n",
      "train accuracy after epoch 43 is 58.294010889292196\n",
      "valid accuracy after epoch 43 is 22.408963585434172\n",
      "train accuracy after epoch 44 is 58.22141560798548\n",
      "valid accuracy after epoch 44 is 20.72829131652661\n",
      "train accuracy after epoch 45 is 58.25771324863884\n",
      "valid accuracy after epoch 45 is 27.45098039215686\n",
      "train accuracy after epoch 46 is 58.98366606170599\n",
      "valid accuracy after epoch 46 is 19.047619047619047\n",
      "train accuracy after epoch 47 is 60.32667876588022\n",
      "valid accuracy after epoch 47 is 21.568627450980394\n",
      "train accuracy after epoch 48 is 60.399274047186935\n",
      "valid accuracy after epoch 48 is 24.369747899159663\n",
      "train accuracy after epoch 49 is 60.14519056261343\n",
      "valid accuracy after epoch 49 is 23.249299719887954\n",
      "train accuracy after epoch 50 is 57.96733212341198\n",
      "valid accuracy after epoch 50 is 24.649859943977592\n",
      "train accuracy after epoch 51 is 60.07259528130672\n",
      "valid accuracy after epoch 51 is 22.969187675070028\n",
      "train accuracy after epoch 52 is 58.475499092558984\n",
      "valid accuracy after epoch 52 is 24.649859943977592\n",
      "train accuracy after epoch 53 is 57.023593466424686\n",
      "valid accuracy after epoch 53 is 20.72829131652661\n",
      "train accuracy after epoch 54 is 60.508166969147005\n",
      "valid accuracy after epoch 54 is 21.568627450980394\n",
      "train accuracy after epoch 55 is 59.455535390199636\n",
      "valid accuracy after epoch 55 is 22.408963585434172\n",
      "train accuracy after epoch 56 is 59.310344827586206\n",
      "valid accuracy after epoch 56 is 26.050420168067227\n",
      "train accuracy after epoch 57 is 60.399274047186935\n",
      "valid accuracy after epoch 57 is 22.408963585434172\n",
      "train accuracy after epoch 58 is 58.294010889292196\n",
      "valid accuracy after epoch 58 is 26.050420168067227\n",
      "train accuracy after epoch 59 is 58.72958257713248\n",
      "valid accuracy after epoch 59 is 26.050420168067227\n",
      "train accuracy after epoch 60 is 58.475499092558984\n",
      "valid accuracy after epoch 60 is 21.84873949579832\n",
      "train accuracy after epoch 61 is 58.91107078039927\n",
      "valid accuracy after epoch 61 is 26.330532212885153\n",
      "train accuracy after epoch 62 is 58.8021778584392\n",
      "valid accuracy after epoch 62 is 21.288515406162464\n",
      "train accuracy after epoch 63 is 59.85480943738657\n",
      "valid accuracy after epoch 63 is 21.568627450980394\n",
      "train accuracy after epoch 64 is 60.798548094373864\n",
      "valid accuracy after epoch 64 is 24.369747899159663\n",
      "train accuracy after epoch 65 is 58.22141560798548\n",
      "valid accuracy after epoch 65 is 27.170868347338935\n",
      "train accuracy after epoch 66 is 58.439201451905625\n",
      "valid accuracy after epoch 66 is 23.529411764705884\n",
      "train accuracy after epoch 67 is 59.23774954627949\n",
      "valid accuracy after epoch 67 is 25.49019607843137\n",
      "train accuracy after epoch 68 is 59.09255898366606\n",
      "valid accuracy after epoch 68 is 24.369747899159663\n",
      "train accuracy after epoch 69 is 60.29038112522686\n",
      "valid accuracy after epoch 69 is 22.689075630252102\n",
      "train accuracy after epoch 70 is 58.8021778584392\n",
      "valid accuracy after epoch 70 is 19.88795518207283\n",
      "train accuracy after epoch 71 is 58.475499092558984\n",
      "valid accuracy after epoch 71 is 22.128851540616246\n",
      "train accuracy after epoch 72 is 59.01996370235935\n",
      "valid accuracy after epoch 72 is 21.288515406162464\n",
      "train accuracy after epoch 73 is 57.277676950998185\n",
      "valid accuracy after epoch 73 is 21.84873949579832\n",
      "train accuracy after epoch 74 is 57.96733212341198\n",
      "valid accuracy after epoch 74 is 21.84873949579832\n",
      "train accuracy after epoch 75 is 56.91470054446461\n",
      "valid accuracy after epoch 75 is 21.568627450980394\n",
      "train accuracy after epoch 76 is 57.78584392014519\n",
      "valid accuracy after epoch 76 is 19.607843137254903\n",
      "train accuracy after epoch 77 is 56.91470054446461\n",
      "valid accuracy after epoch 77 is 22.689075630252102\n",
      "train accuracy after epoch 78 is 57.93103448275862\n",
      "valid accuracy after epoch 78 is 26.89075630252101\n",
      "train accuracy after epoch 79 is 59.346642468239565\n",
      "valid accuracy after epoch 79 is 22.408963585434172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy after epoch 80 is 59.201451905626136\n",
      "valid accuracy after epoch 80 is 21.568627450980394\n",
      "train accuracy after epoch 81 is 56.91470054446461\n",
      "valid accuracy after epoch 81 is 23.249299719887954\n",
      "train accuracy after epoch 82 is 58.69328493647913\n",
      "valid accuracy after epoch 82 is 21.568627450980394\n",
      "train accuracy after epoch 83 is 59.382940108892925\n",
      "valid accuracy after epoch 83 is 23.80952380952381\n",
      "train accuracy after epoch 84 is 57.56805807622504\n",
      "valid accuracy after epoch 84 is 21.568627450980394\n",
      "train accuracy after epoch 85 is 57.85843920145191\n",
      "valid accuracy after epoch 85 is 23.529411764705884\n",
      "train accuracy after epoch 86 is 57.56805807622504\n",
      "valid accuracy after epoch 86 is 22.969187675070028\n",
      "train accuracy after epoch 87 is 58.87477313974592\n",
      "valid accuracy after epoch 87 is 23.529411764705884\n",
      "train accuracy after epoch 88 is 58.22141560798548\n",
      "valid accuracy after epoch 88 is 20.168067226890756\n",
      "train accuracy after epoch 89 is 56.91470054446461\n",
      "valid accuracy after epoch 89 is 22.969187675070028\n",
      "train accuracy after epoch 90 is 55.8983666061706\n",
      "valid accuracy after epoch 90 is 22.408963585434172\n",
      "train accuracy after epoch 91 is 56.73321234119782\n",
      "valid accuracy after epoch 91 is 21.84873949579832\n",
      "train accuracy after epoch 92 is 56.116152450090745\n",
      "valid accuracy after epoch 92 is 26.89075630252101\n",
      "train accuracy after epoch 93 is 54.08348457350272\n",
      "valid accuracy after epoch 93 is 25.210084033613445\n",
      "train accuracy after epoch 94 is 55.93466424682396\n",
      "valid accuracy after epoch 94 is 24.92997198879552\n",
      "train accuracy after epoch 95 is 56.33393829401089\n",
      "valid accuracy after epoch 95 is 27.73109243697479\n",
      "train accuracy after epoch 96 is 57.93103448275862\n",
      "valid accuracy after epoch 96 is 23.80952380952381\n",
      "train accuracy after epoch 97 is 55.57168784029038\n",
      "valid accuracy after epoch 97 is 22.969187675070028\n",
      "train accuracy after epoch 98 is 51.50635208711434\n",
      "valid accuracy after epoch 98 is 27.73109243697479\n",
      "train accuracy after epoch 99 is 51.97822141560798\n",
      "valid accuracy after epoch 99 is 23.80952380952381\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    train(train_dataloader,epoch)\n",
    "    validation(val_dataloader,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3]) tensor([5])\n",
      "tensor([6]) tensor([5])\n",
      "tensor([0]) tensor([2])\n",
      "tensor([3]) tensor([5])\n",
      "tensor([4]) tensor([2])\n",
      "tensor([1]) tensor([5])\n",
      "tensor([6]) tensor([5])\n",
      "tensor([0]) tensor([2])\n",
      "tensor([4]) tensor([2])\n",
      "tensor([6]) tensor([5])\n",
      "tensor([0]) tensor([5])\n",
      "tensor([0]) tensor([4])\n",
      "tensor([3]) tensor([2])\n",
      "tensor([1]) tensor([5])\n",
      "tensor([5]) tensor([5])\n",
      "tensor([0]) tensor([2])\n",
      "tensor([3]) tensor([5])\n",
      "tensor([3]) tensor([5])\n",
      "tensor([1]) tensor([5])\n",
      "tensor([5]) tensor([5])\n",
      "tensor([0]) tensor([2])\n",
      "tensor([3]) tensor([2])\n",
      "tensor([2]) tensor([5])\n",
      "tensor([4]) tensor([2])\n",
      "tensor([1]) tensor([5])\n",
      "tensor([3]) tensor([5])\n",
      "tensor([1]) tensor([5])\n",
      "tensor([6]) tensor([5])\n",
      "tensor([0]) tensor([4])\n",
      "tensor([1]) tensor([5])\n",
      "tensor([5]) tensor([5])\n",
      "tensor([0]) tensor([4])\n",
      "tensor([3]) tensor([5])\n",
      "tensor([1]) tensor([5])\n",
      "tensor([0]) tensor([3])\n",
      "tensor([4]) tensor([3])\n",
      "tensor([1]) tensor([5])\n",
      "tensor([0]) tensor([4])\n",
      "3 38\n",
      "7.894736842105263\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(testloader):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        labels = torch.argmax(labels,dim =1)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(labels,predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(correct,total)\n",
    "print(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTL_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path, test_key,valid_key, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.files = os.listdir(self.dir_path)\n",
    "        self.test_key = test_key\n",
    "        self.valid_key = valid_key\n",
    "        self.melspecs,self.Y = self.loadData(dir_path)\n",
    "        print(len(self.melspecs),len(self.Y))\n",
    "        \n",
    "    def loadData(self,dir_path):\n",
    "        files = os.listdir(dir_path)\n",
    "        train_keys = list((spk_id[i] for i in range(10) if i not in [self.test_key,self.valid_key]))\n",
    "        melspecs = []\n",
    "        Y = []\n",
    "        for key in train_keys:\n",
    "            for file in files:\n",
    "                if file[:2]==key:\n",
    "                    r, sr = librosa.load(dir_path + file, res_type='kaiser_fast')\n",
    "                    melspec = librosa.feature.melspectrogram(y=r, sr=sr,n_fft = 512, hop_length=160, win_length=320,n_mels=24)\n",
    "                    temp = self.chunk(torch.Tensor(melspec))\n",
    "                    melspecs.extend(temp)\n",
    "                    for _ in range(len(temp)):\n",
    "                        ye = torch.zeros(7,dtype = int)\n",
    "                        ye[emotion_code[file[5]]]=1\n",
    "                        yg = torch.zeros(2,dtype = int)\n",
    "                        yg[gender_code[file[:2]]]=1\n",
    "                        Y.append((ye,yg))\n",
    "        return melspecs,Y\n",
    "    \n",
    "    def chunk(self,melspec):\n",
    "        melspec = melspec.transpose(0,1)\n",
    "        res = []\n",
    "        for i in range(0,melspec.size(0),50):\n",
    "            temp = melspec[i:i+100,:]\n",
    "            if temp.size(0)==100:\n",
    "                res.append(temp)\n",
    "        return res        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.melspecs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.melspecs[idx],self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2629 2629\n"
     ]
    }
   ],
   "source": [
    "trmt = MTL_Dataset(\"EmoDB/wav/\",0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmt_dataloader = DataLoader(trmt, batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTLVal_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path,valid_key, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.files = os.listdir(self.dir_path)\n",
    "        self.valid_key = valid_key\n",
    "        self.melspecs,self.Y = self.loadData(dir_path)\n",
    "        print(len(self.melspecs),len(self.Y))\n",
    "        \n",
    "    def loadData(self,dir_path):\n",
    "        files = os.listdir(dir_path)\n",
    "        melspecs = []\n",
    "        Y = []\n",
    "        for file in files:\n",
    "            if file[:2]==spk_id[self.valid_key]:\n",
    "                r, sr = librosa.load(dir_path + file, res_type='kaiser_fast')\n",
    "                melspec = librosa.feature.melspectrogram(y=r, sr=sr,n_fft = 512, hop_length=160, win_length=320,n_mels=24)\n",
    "                temp = self.chunk(torch.Tensor(melspec))\n",
    "                melspecs.extend(temp)\n",
    "                for _ in range(len(temp)):\n",
    "                    ye = torch.zeros(7,dtype = int)\n",
    "                    ye[emotion_code[file[5]]]=1\n",
    "                    yg = torch.zeros(2,dtype = int)\n",
    "                    yg[gender_code[file[:2]]]=1\n",
    "                    Y.append((ye,yg))\n",
    "        return melspecs,Y\n",
    "    \n",
    "    def chunk(self,melspec):\n",
    "        melspec = melspec.transpose(0,1)\n",
    "        res = []\n",
    "        for i in range(0,melspec.size(0),50):\n",
    "            temp = melspec[i:i+100,:]\n",
    "            if temp.size(0)==100:\n",
    "                res.append(temp)\n",
    "        return res        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.melspecs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.melspecs[idx],self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 399\n"
     ]
    }
   ],
   "source": [
    "vmt = MTLVal_Dataset(\"EmoDB/wav/\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "validmt_dataloader = DataLoader(vmt, batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTLTest_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path,test_key, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.files = os.listdir(self.dir_path)\n",
    "        self.test_key = test_key\n",
    "        self.melspecs,self.Y = self.loadData(dir_path)\n",
    "        print(len(self.melspecs),len(self.Y))\n",
    "        \n",
    "    def loadData(self,dir_path):\n",
    "        files = os.listdir(dir_path)\n",
    "        melspecs = []\n",
    "        Y = []\n",
    "        for file in files:\n",
    "            if file[:2]==spk_id[self.test_key]:\n",
    "                r, sr = librosa.load(dir_path + file, res_type='kaiser_fast')\n",
    "                melspec = librosa.feature.melspectrogram(y=r, sr=sr,n_fft = 512, hop_length=160, win_length=320,n_mels=24)\n",
    "                melspec = melspec.transpose()\n",
    "                melspecs.append(melspec)\n",
    "                ye = torch.zeros(7,dtype = int)\n",
    "                ye[emotion_code[file[5]]]=1\n",
    "                yg = torch.zeros(2,dtype = int)\n",
    "                yg[gender_code[file[:2]]]=1\n",
    "                Y.append((ye,yg))\n",
    "        return melspecs,Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.melspecs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.melspecs[idx],self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 49\n"
     ]
    }
   ],
   "source": [
    "testmt = MTLTest_Dataset(\"EmoDB/wav/\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmt_dataloader = DataLoader(testmt, batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multitask(nn.Module):\n",
    "    def __init__(self, input_dim = 24, em_classes=7,gen_classes = 2):\n",
    "        super(multitask, self).__init__()\n",
    "        self.tdnn1 = TDNN(input_dim=input_dim, output_dim=512, context_size=5, dilation=1,dropout_p=0.5)\n",
    "        self.tdnn2 = TDNN(input_dim=512, output_dim=512, context_size=3, dilation=1,dropout_p=0.5)\n",
    "        self.tdnn3 = TDNN(input_dim=512, output_dim=512, context_size=2, dilation=2,dropout_p=0.5)\n",
    "        self.tdnn4 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=1,dropout_p=0.5)\n",
    "        self.tdnn5 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=3,dropout_p=0.5)\n",
    "        #### Frame levelPooling\n",
    "        self.segment6 = nn.Linear(1024, 512)\n",
    "        self.segment7 = nn.Linear(512, 512)\n",
    "        self.emotion = nn.Linear(512, em_classes)\n",
    "        self.gender = nn.Linear(512, gen_classes)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, inputs):\n",
    "        tdnn1_out = self.tdnn1(inputs)\n",
    "#         return tdnn1_out\n",
    "        tdnn2_out = self.tdnn2(tdnn1_out)\n",
    "        tdnn3_out = self.tdnn3(tdnn2_out)\n",
    "        tdnn4_out = self.tdnn4(tdnn3_out)\n",
    "        tdnn5_out = self.tdnn5(tdnn4_out)\n",
    "        ### Stat Pool\n",
    "        mean = torch.mean(tdnn5_out,1)\n",
    "        std = torch.std(tdnn5_out,1)\n",
    "        stat_pooling = torch.cat((mean,std),1)\n",
    "        segment6_out = self.segment6(stat_pooling)\n",
    "        x_vec = self.segment7(segment6_out)\n",
    "        em_predictions = self.emotion(x_vec)\n",
    "        gen_predictions = self.gender(x_vec)\n",
    "        return em_predictions,gen_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0098, -0.0171, -0.0305, -0.0194, -0.0344,  0.0426,  0.0026],\n",
      "        [-0.0093, -0.0194, -0.0295, -0.0188, -0.0358,  0.0425,  0.0020],\n",
      "        [-0.0084, -0.0177, -0.0309, -0.0175, -0.0381,  0.0416,  0.0036],\n",
      "        [-0.0101, -0.0168, -0.0309, -0.0189, -0.0360,  0.0429,  0.0039]],\n",
      "       grad_fn=<AddmmBackward>), tensor([[0.0078, 0.0154],\n",
      "        [0.0082, 0.0159],\n",
      "        [0.0083, 0.0154],\n",
      "        [0.0078, 0.0159]], grad_fn=<AddmmBackward>))\n"
     ]
    }
   ],
   "source": [
    "input_feats = [4,100,24]\n",
    "input = torch.rand(input_feats)\n",
    "mt_model = multitask()\n",
    "out = mt_model(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmt(train_dataloader,epoch):\n",
    "    running_loss = 0.0\n",
    "    train_loss_list=[]\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs.requires_grad = True\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        labels[0] = torch.argmax(labels[0],dim =1)\n",
    "        labels[1] = torch.argmax(labels[1],dim =1)\n",
    "        # forward + backward + optimize\n",
    "        outputs = mt_model(inputs)\n",
    "        loss1 = criterion(outputs[0], labels[0])\n",
    "        loss2 = criterion(outputs[1], labels[1])\n",
    "        loss = loss1+loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "        mean_loss = np.mean(np.asarray(train_loss_list))\n",
    "        if i%100==0:\n",
    "            print('Iteration - {} Epoch - {} Total training loss - {} '.format(i,epoch,mean_loss))\n",
    "            \n",
    "def validationmt(valid_dataloader,epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss_list=[]\n",
    "        for i, data in enumerate(valid_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            labels[0] = torch.argmax(labels[0],dim =1)\n",
    "            labels[1] = torch.argmax(labels[1],dim =1)\n",
    "            outputs = mt_model(inputs)\n",
    "            loss1 = criterion(outputs[0], labels[0])\n",
    "            loss2 = criterion(outputs[1], labels[1])\n",
    "            loss = loss1+loss2\n",
    "            val_loss_list.append(loss.item())\n",
    "            if i%100==0:\n",
    "                print('Iteration - {} Epoch - {} Loss - {}'.format(i,epoch,np.mean(np.asarray(val_loss_list))))\n",
    "                \n",
    "        mean_loss = np.mean(np.asarray(val_loss_list))\n",
    "        print('Total validation loss {} after {} epochs'.format(mean_loss,epoch))\n",
    "        model_save_path = os.path.join( 'best_check_point_'+str(epoch)+'_'+str(mean_loss))\n",
    "        state_dict = {'model': model.state_dict(),'optimizer': optimizer.state_dict(),'epoch': epoch}\n",
    "        torch.save(state_dict, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    trainmt(trainmt_dataloader,epoch)\n",
    "    validationmt(validmt_dataloader,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(testmt_dataloader):\n",
    "        inputs, labels = data\n",
    "        labels[0] = torch.argmax(labels[0],dim =1)\n",
    "        labels[1] = torch.argmax(labels[1],dim =1)\n",
    "        outputs = mt_model(inputs)\n",
    "        print(outputs,labels)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "# print(correct,total)\n",
    "# print(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
